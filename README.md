# AI Concepts Hub ðŸš€
A collection of AI/ML concepts explained through code and visualizations. This repository serves as an index linking to detailed implementations of various AI concepts.

## ðŸ“Œ Topics Covered

### 1. Self-Attention Mechanism
ðŸ“– **Description:** An in-depth exploration of self-attention in transformers, demonstrating step-by-step how self-attention works using Python code, along with practical explanations and real-world applications.

ðŸ”— **Repo:** [Self-Attention Tutorial](https://github.com/mdabdulrazzaq/transformer-self-attention)

### 2. Multi-Head Attention in Transformers
ðŸ“– **Description:** A detailed look into the mechanics of self-attention in transformers, including core attention mechanisms, linear projections, scaled dot products, and attention weighting, with demonstrations of single-head and multi-head attention mechanisms.

ðŸ”— **Repo:** [Transformer Multi-Head Attention](https://github.com/mdabdulrazzaq/Transformer-Multi-Head-Attention)

### 3. Word Embeddings in NLP
ðŸ“– **Description:** A project focused on word embeddings, illustrating how words can be represented as vectors in a continuous vector space to capture semantic relationships.

ðŸ”— **Repo:** [NLP Day 2: Word Embeddings](https://github.com/mdabdulrazzaq/NLP-DAY2-wordembeddings)

### 4. Text Preprocessing in NLP
ðŸ“– **Description:** A comprehensive guide on text preprocessing techniques, including tokenization, stop-word removal, stemming, and lemmatization, essential for preparing text data for analysis.

ðŸ”— **Repo:** [NLP Day 1: Text Preprocessing](https://github.com/mdabdulrazzaq/NLP-Day-1-Project)

## ðŸš€ How to Use
Click on any topic to visit its dedicated repository, where youâ€™ll find detailed explanations, code, and visualizations.

## ðŸ“¢ Contribute
Have an AI concept you'd like to add? Feel free to suggest or open a pull request!

## ðŸ“œ License
MIT License
